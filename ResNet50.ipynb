{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Resnet-50**"
      ],
      "metadata": {
        "id": "JznXe32ImIoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import time\n",
        "from torchvision import models"
      ],
      "metadata": {
        "id": "5iX8JQuoOWA5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "BOqeCTLdOpJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Uat3Kw6YQdnG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mcagriaksoy/trees-in-satellite-imagery"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3z5U81DQiRq",
        "outputId": "b58dfe7d-c19d-44aa-874e-4746b65b990e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mcagriaksoy/trees-in-satellite-imagery\n",
            "License(s): CC-BY-NC-SA-4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(\"trees-in-satellite-imagery.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"trees_dataset\")\n",
        "\n",
        "print(\"Dataset extracted successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQFnoFrUQmJf",
        "outputId": "91495a35-401c-424f-ff13-d44786ccbf0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (resize, normalize, augment)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),  # Augmentation\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Slight shift\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"trees_dataset/Trees in Satellite Imagery\"\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Split into training (80%) and validation (20%)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Check class labels\n",
        "print(\"Class Mapping:\", dataset.class_to_idx)  # {'NoTree': 0, 'Tree': 1}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLqvuAxhE3Sn",
        "outputId": "60d06416-6ad7-4e2d-a294-337ae6ec0e50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Mapping: {'NoTrees': 0, 'Trees': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet-50 pre-trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)  # Load ResNet-50\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)  # Modify final layer for binary classification\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"ResNet-50 Model Ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk45LVKSoJLf",
        "outputId": "1751e672-5ca4-456f-e00e-a247eae38862"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 Model Ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=20):\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"best_resnet50_tree_model.pth\")\n",
        "            print(f\"Best model saved at epoch {epoch+1} with Val Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "print(\"Training ResNet-50 on Tree Dataset\")\n",
        "model = train_model(model, train_loader, val_loader, num_epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgljCkByoMqm",
        "outputId": "0463025a-16b3-41d3-a76d-0e83665527cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet-50 on Tree Dataset\n",
            "Epoch [1/20], Train Loss: 20.0177, Val Loss: 3.1334, Val Accuracy: 98.22%\n",
            "Best model saved at epoch 1 with Val Accuracy: 98.22%\n",
            "Epoch [2/20], Train Loss: 14.4941, Val Loss: 2.8597, Val Accuracy: 98.46%\n",
            "Best model saved at epoch 2 with Val Accuracy: 98.46%\n",
            "Epoch [3/20], Train Loss: 16.2495, Val Loss: 4.3631, Val Accuracy: 98.08%\n",
            "Epoch [4/20], Train Loss: 16.4933, Val Loss: 3.2786, Val Accuracy: 98.37%\n",
            "Epoch [5/20], Train Loss: 13.4217, Val Loss: 3.7944, Val Accuracy: 98.03%\n",
            "Epoch [6/20], Train Loss: 15.5407, Val Loss: 3.3744, Val Accuracy: 98.22%\n",
            "Epoch [7/20], Train Loss: 13.8504, Val Loss: 4.1279, Val Accuracy: 97.64%\n",
            "Epoch [8/20], Train Loss: 13.2870, Val Loss: 3.1954, Val Accuracy: 98.27%\n",
            "Epoch [9/20], Train Loss: 13.7899, Val Loss: 3.1353, Val Accuracy: 98.37%\n",
            "Epoch [10/20], Train Loss: 13.9056, Val Loss: 3.2916, Val Accuracy: 97.84%\n",
            "Epoch [11/20], Train Loss: 11.6771, Val Loss: 2.3104, Val Accuracy: 98.85%\n",
            "Best model saved at epoch 11 with Val Accuracy: 98.85%\n",
            "Epoch [12/20], Train Loss: 11.5236, Val Loss: 2.5681, Val Accuracy: 98.80%\n",
            "Epoch [13/20], Train Loss: 11.6620, Val Loss: 2.9663, Val Accuracy: 98.41%\n",
            "Epoch [14/20], Train Loss: 13.2905, Val Loss: 4.0117, Val Accuracy: 97.84%\n",
            "Epoch [15/20], Train Loss: 10.9614, Val Loss: 2.4180, Val Accuracy: 98.56%\n",
            "Epoch [16/20], Train Loss: 10.4265, Val Loss: 2.9136, Val Accuracy: 98.32%\n",
            "Epoch [17/20], Train Loss: 11.3797, Val Loss: 3.1197, Val Accuracy: 97.88%\n",
            "Epoch [18/20], Train Loss: 9.4239, Val Loss: 3.4596, Val Accuracy: 98.17%\n",
            "Epoch [19/20], Train Loss: 9.3290, Val Loss: 2.5300, Val Accuracy: 98.61%\n",
            "Epoch [20/20], Train Loss: 9.5982, Val Loss: 2.9877, Val Accuracy: 98.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"best_resnet50_tree_model.pth\"))\n",
        "model.eval()  # Set to evaluation mode\n",
        "print(\"Best ResNet-50 Model Loaded for Evaluation!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRdJtKGLspe6",
        "outputId": "776f6adf-5ed1-4622-a490-8a6492f92d74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ResNet-50 Model Loaded for Evaluation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Collect true labels and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:  # Using validation dataset\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Compute Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Tree\", \"Tree\"], yticklabels=[\"No Tree\", \"Tree\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_true, y_pred, target_names=[\"No Tree\", \"Tree\"])\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "TwPw9qVJsvU3",
        "outputId": "ca5d8229-5d4a-4ff3-8bb6-11f15cfcd253"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 98.61%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     No Tree       0.98      0.99      0.99      1035\n",
            "        Tree       0.99      0.98      0.99      1045\n",
            "\n",
            "    accuracy                           0.99      2080\n",
            "   macro avg       0.99      0.99      0.99      2080\n",
            "weighted avg       0.99      0.99      0.99      2080\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create a synthetic image tensor (1 image, 3 color channels, 224x224 resolution)\n",
        "synthetic_image = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "def measure_inference_time(model, model_name):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Warm-up (Run the model a few times before measuring for accuracy)\n",
        "    for _ in range(5):\n",
        "        with torch.no_grad():\n",
        "            _ = model(synthetic_image)\n",
        "\n",
        "    # Measure actual inference time\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        _ = model(synthetic_image)\n",
        "    end_time = time.time()\n",
        "\n",
        "    inference_time = end_time - start_time\n",
        "    print(f\"{model_name} Inference Time: {inference_time:.6f} seconds\")\n",
        "\n",
        "# Load and test ResNet-50\n",
        "resnet50_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "resnet50_model.fc = torch.nn.Linear(resnet50_model.fc.in_features, 2)\n",
        "measure_inference_time(resnet50_model, \"ResNet-50\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-gWdTXsu0EV",
        "outputId": "7a473888-d792-4f89-9215-e079ea2792f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet-50 Inference Time: 0.007060 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model, model_name):\n",
        "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
        "    size = os.path.getsize(f\"{model_name}.pth\") / 1024 / 1024  # Convert to MB\n",
        "    os.remove(f\"{model_name}.pth\")\n",
        "    print(f\"{model_name} Size: {size:.2f} MB\")\n",
        "\n",
        "# Measure size of  model\n",
        "get_model_size(resnet50_model, \"ResNet-50\")\n"
      ],
      "metadata": {
        "id": "V1pqzF-_0_TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet-50 model\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9IrW6ccM9oG",
        "outputId": "69d6fd67-14f5-493c-d584-6f0153c0a00a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}